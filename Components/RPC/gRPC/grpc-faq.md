## 1. Method Not Found

### 1. 错误描述

在使用`gPRC`时遇到的问题。

其中客户端由`golang`编写，服务端由`python`编写。

测试时一直报如下这个错：

```go
rpc error:Code=Unimplemented desc = Method Not Found！
```

下面是官网上的错误列表，其中`GRPC_STATUS_UNIMPLEMENTED`对应的case也是`Method not found on server`。

| Case                                                         | Status code                   |
| :----------------------------------------------------------- | :---------------------------- |
| Client application cancelled the request                     | GRPC_STATUS_CANCELLED         |
| Deadline expired before server returned status               | GRPC_STATUS_DEADLINE_EXCEEDED |
| Method not found on server                                   | GRPC_STATUS_UNIMPLEMENTED     |
| Server shutting down                                         | GRPC_STATUS_UNAVAILABLE       |
| Server threw an exception (or did something other than returning a status code to terminate the RPC) | GRPC_STATUS_UNKNOWN           |



>  但是 单独测试时 `python`自己写的客户端服务端可以正常交互

`golang`写的客户端 服务端也可以正常交互。

就是两个互相调用时会出现这个错误`Method Not Found`

仔细检查代码之后并没有什么问题。

各种`google`之后总算找到了原因。

`https://www.itread01.com/content/1547029280.html`

### 原因

`这是由于`.proto文件`中的`package name` 被修改，和 server 端的package 不一致导致的,双方同步`.proto文件` packagename` 重新编译生成对应的代码即可。

由于python写时没有加`package xxx;`这就 然后go这边加了。。。怪不得会出错，果然在修改`.proto文件`从新编译后就能成功运行了。



## 2. 数据传输限制

### 1. 错误描述

```sh
details = "Received message larger than max (6194304 vs. 4194304)"
```

接收消息超过了最大限制(默认4M)



### 2. 解决

可以在建立连接的时候修改这个限制。

#### server

```go
maxSize := 20 * 1024 * 1024
s := grpc.NewServer(grpc.MaxRecvMsgSize(maxSize), grpc.MaxSendMsgSize(maxSize))
PbDownMaxSize.RegisterPbDownMaxSizeServer(s, &server{})
s.Serve(listener)
```

#### client

```go
maxSize := 20 * 1024 * 1024
diaOpt := grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxSize), grpc.MaxCallSendMsgSize(maxSize))
conn, err := grpc.Dial(endpoint, grpc.WithInsecure(), diaOpt)
```

### 3. 源码

#### RecvMsg

```go
func (p *parser) recvMsg(maxReceiveMessageSize int) (pf payloadFormat, msg []byte, err error) {
	if _, err := p.r.Read(p.header[:]); err != nil {
		return 0, nil, err
	}

	pf = payloadFormat(p.header[0])
	length := binary.BigEndian.Uint32(p.header[1:])

	if length == 0 {
		return pf, nil, nil
	}
	if int64(length) > int64(maxInt) {
		return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max length allowed on current machine (%d vs. %d)", length, maxInt)
	}
	if int(length) > maxReceiveMessageSize {
		return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max (%d vs. %d)", length, maxReceiveMessageSize)
	}
	// TODO(bradfitz,zhaoq): garbage. reuse buffer after proto decoding instead
	// of making it for each message:
	msg = make([]byte, int(length))
	if _, err := p.r.Read(msg); err != nil {
		if err == io.EOF {
			err = io.ErrUnexpectedEOF
		}
		return 0, nil, err
	}
	return pf, msg, nil
}
```
可以看到在Recv的时候判定了两次数据长度。

除了设置的长度外还有一个最大长度限制`int64(length) > int64(maxInt)`

```go
	if int64(length) > int64(maxInt) {
		return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max length allowed on current machine (%d vs. %d)", length, maxInt)
	}
	if int(length) > maxReceiveMessageSize {
		return 0, nil, status.Errorf(codes.ResourceExhausted, "grpc: received message larger than max (%d vs. %d)", length, maxReceiveMessageSize)
	}
```

最大限制`const maxInt = int(^uint(0) >> 1)`应该是2G大小。

> 不会有人拿gPRC传这么大的数据吧...

#### SendMsg

```go
func (cs *clientStream) SendMsg(m interface{}) (err error) {
	defer func() {
		if err != nil && err != io.EOF {
			// Call finish on the client stream for errors generated by this SendMsg
			// call, as these indicate problems created by this client.  (Transport
			// errors are converted to an io.EOF error in csAttempt.sendMsg; the real
			// error will be returned from RecvMsg eventually in that case, or be
			// retried.)
			cs.finish(err)
		}
	}()
	if cs.sentLast {
		return status.Errorf(codes.Internal, "SendMsg called after CloseSend")
	}
	if !cs.desc.ClientStreams {
		cs.sentLast = true
	}

	// load hdr, payload, data
	hdr, payload, data, err := prepareMsg(m, cs.codec, cs.cp, cs.comp)
	if err != nil {
		return err
	}

	// TODO(dfawley): should we be checking len(data) instead?
	if len(payload) > *cs.callInfo.maxSendMessageSize {
		return status.Errorf(codes.ResourceExhausted, "trying to send message larger than max (%d vs. %d)", len(payload), *cs.callInfo.maxSendMessageSize)
	}
	msgBytes := data // Store the pointer before setting to nil. For binary logging.
	op := func(a *csAttempt) error {
		err := a.sendMsg(m, hdr, payload, data)
		// nil out the message and uncomp when replaying; they are only needed for
		// stats which is disabled for subsequent attempts.
		m, data = nil, nil
		return err
	}
	err = cs.withRetry(op, func() { cs.bufferForRetryLocked(len(hdr)+len(payload), op) })
	if cs.binlog != nil && err == nil {
		cs.binlog.Log(&binarylog.ClientMessage{
			OnClientSide: true,
			Message:      msgBytes,
		})
	}
	return
}
```

同理发送的时候也有这个限制

```go
	if len(payload) > *cs.callInfo.maxSendMessageSize {
		return status.Errorf(codes.ResourceExhausted, "trying to send message larger than max (%d vs. %d)", len(payload), *cs.callInfo.maxSendMessageSize)
	}
```



## 3. 请求超时

查看日志发现总是会出现一些请求超时，而且是一阵一阵的，对比了请求量，发现超时的都是在并发较高的时间段。

查看了 Pod 的 CPU、网络、内存都很正常，没有一点压力。

再次查看连接数限制也远远没有达到上限

```sh
$ ulimit -Sn
1048576
$ ulimit -Hn
1048576
```

而且 gRPC 是基于 HTTP/2 的，连接可以复用，也不会创建太多的连接。

最后发现是 HTTP/2 有并发流限制，具体见该[文档](https://docs.microsoft.com/zh-cn/aspnet/core/grpc/performance?view=aspnetcore-5.0)

HTTP/2 连接通常会限制一个连接上同时存在的[最大并发流（活动 HTTP 请求）数](https://httpwg.github.io/specs/rfc7540.html#rfc.section.5.1.2)。 默认情况下，大多数服务器将此限制设置为 100 个并发流。

go中的http2默认并发流是设置的 250 个

```go
const (
	defaultMaxStreams      = 250 // TODO: make this 100 as the GFE seems to?
)
```

gRPC-go 中也提供了对应的设置项：

```go
grpc.MaxConcurrentStreams(10000)
```

如果没有设置则会使用 [HTTP2 包](https://github.com/golang/net/blob/master/http2/server.go#L56)中的 250 的上限。

不过gRPC-go [在某次更新后](https://github.com/grpc/grpc-go/issues/1986)已经取消了该限制，默认时设置的 math.MaxUint32 数，源码如下：

```go
	maxStreams := config.MaxStreams
	if maxStreams == 0 {
		maxStreams = math.MaxUint32
	} else {
		isettings = append(isettings, http2.Setting{
			ID:  http2.SettingMaxConcurrentStreams,
			Val: maxStreams,
		})
	}
```



* 1）客户端同时启动了过多 Goroutine，并发请求，导致请求在客户端就被阻塞了
  * todo
* 2）服务端同时接受太多请求，无法处理
  * 设置最大连接数`grpc.MaxConcurrentStreams(10000)`可以解决该问题，达到最大并发数后续的请求会在客户端排队