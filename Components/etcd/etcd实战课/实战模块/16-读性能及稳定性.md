# 性能及稳定性

## 1. 性能分析链路

以下是一个开启密码鉴权场景的读性能瓶颈分析链路图，并在每个核心步骤数字旁边，标出了影响性能的关键因素。

![](assets/performance/read-process.png)



### 1.1 负载均衡

在 etcd 3.4 后前client 为了节省与 server 节点的连接数，clientv3 负载均衡器最终只会选择一个 sever 节点 IP，与其建立一个长连接。但是这可能会导致对应的 server 节点过载（如单节点流量过大，出现丢包）， 其他节点却是低负载，最终导致业务无法获得集群的最佳性能。

在 etcd 3.4 后，引入了 Round-robin 负载均衡算法，它通过轮询的方式依次从 endpoint 列表中选择一个 endpoint 访问 (长连接)，使 server 节点负载尽量均衡。



### 1.2 鉴权

选择好 server 之后就进行到流程2鉴权。

如果 server 使用的是密码鉴权，你在创建 client 时，需指定用户名和密码。etcd clientv3 库发现用户名、密码非空，就会先校验用户名和密码是否正确。

server 节点收到鉴权请求后，它会从 boltdb 获取此用户密码对应的算法版本、salt、cost 值，并基于用户的请求明文密码计算出一个 hash 值。

在得到 hash 值后，就可以对比 db 里保存的 hash 密码是否与其一致了。如果一致，就会返回一个 token 给 client。 这个 token 是 client 访问 server 节点的通行证，后续 server 只需要校验“通行证”是否有效即可，无需每次发起昂贵的 Authenticate RPC 请求。

> 若你的业务在访问 etcd 过程中未复用 token，每次访问 etcd 都发起一次 Authenticate 调用，这将是一个非常大的性能瓶颈和隐患。为了保证密码的安全性，密码认证（Authenticate）的开销非常昂贵，涉及到大量 CPU 资源。

16核32G 机器的压测结果表明，在 etcd 3.4.9 之前 Authenticate QPS 只有10几，在 3.4.9版本 [优化](https://github.com/etcd-io/etcd/pull/11735)到了 200左右。

> 由于导致 Authenticate 接口性能差的核心瓶颈，是在于密码鉴权使用了 bcrpt 计算 hash 值，因此 Authenticate 性能已接近极限。

因此鉴权也可能是性能瓶颈，使用建议：

* 第一，如果你的生产环境需要开启鉴权，并且读写 QPS 较大，那我建议你不要图省事使用密码鉴权。**最好使用证书鉴权**，这样能完美避坑认证性能差、token 过期等问题，性能几乎无损失。
  * 证书只需要在建立 HTTPS 连接的时候进行鉴权，后续复用连接就不需要鉴权了，所以相密码鉴权提升很大
* 第二，确保你的业务每次发起请求时有**复用 token** 机制，尽可能减少 Authenticate RPC 调用。
* 第三，如果你使用密码鉴权时遇到性能瓶颈问题，可**将 etcd 升级到 3.4.9 及以上版本**，能适当提升密码鉴权的性能。



### 1.3 选择合适的读模式

client 通过 server 的鉴权后，就可以发起读请求调用了，也就是我们图中的流程三。

 etcd 提供了串行读和线性读两种读模式。

* 串行读因为不经过 ReadIndex 模块，具有低延时、高吞吐量的特点；
* 线性读在牺牲一点延时和吞吐量的基础上，实现了数据的强一致性读。

这两种读模式分别为不同场景的读提供了解决方案。

根据[社区压测结果](https://etcd.io/docs/v3.4/op-guide/performance/)显示，**串行读QPS几乎时线性读的两倍**。

如果业务可以容忍短暂的不一致，那么可以通过串行读来提升 etcd 的读性能。



### 1.4 线性读实现机制、网络延时

线性读对应图中的流程四、流程五，其中流程四对应的是 ReadIndex，流程五对应的是等待本节点数据追上 Leader 的进度（ApplyWait）。

在早期的 etcd 3.0 版本中，etcd 线性读是基于 Raft log read 实现的。每次读请求要像写请求一样，生成一个 Raft 日志条目，然后提交给 Raft 一致性模块处理，基于 Raft 日志执行的有序性来实现线性读。因为该过程需要经过磁盘 I/O，所以性能较差。

etcd 3.1 中引入了 ReadIndex。ReadIndex 仅涉及到各个节点之间网络通信，因此节点之间的 RTT 延时对其性能有较大影响。虽然同可用区可获取到最佳性能，但是存在单可用区故障风险。如果你想实现高可用区容灾的话，那就必须牺牲一点性能了。

各个节点之间的 RTT 延时，是决定流程四 ReadIndex 性能的核心因素之一。



### 1.5 磁盘 IO 性能、写 QPS

到了流程五，影响性能的核心因素就是磁盘 IO 延时和写 QPS。

流程五是指节点从 Leader 获取到最新已提交的日志条目索引 (rs.Index) 后，它需要等待本节点当前已应用的 Raft 日志索引，大于等于 Leader 的已提交索引，确保能在本节点状态机中读取到最新数据。

```go
if ai := s.getAppliedIndex(); ai < rs.Index {
   select {
   case <-s.applyWait.Wait(rs.Index):
   case <-s.stopping:
      return
   }
}
// unblock all l-reads requested at indices before rs.Index
nr.notify(nil)
```

而应用已提交日志条目到状态机的过程中又涉及到随机写磁盘.

因此：**etcd 是一个对磁盘 IO 性能非常敏感的存储系统，磁盘 IO 性能不仅会影响 Leader 稳定性、写性能表现，还会影响读性能。线性读性能会随着写性能的增加而快速下降。如果业务对性能、稳定性有较大要求，我建议你尽量使用 SSD 盘**。



### 1.6 RBAC 规则数、Auth 锁

读请求到了 MVCC 模块后，首先要通过鉴权模块判断此用户是否有权限访问请求的数据路径，也就是流程六。影响流程六的性能因素是你的 RBAC 规则数和锁。

首先是 RBAC 规则数，为了解决快速判断用户对指定 key 范围是否有权限，etcd 为每个用户维护了读写权限区间树。基于区间树判断用户访问的范围是否在用户的读写权限区间内，时间复杂度仅需要 O(logN)。

另外一个因素则是 AuthStore 的锁。在 etcd 3.4.9 之前的，校验密码接口可能会占用较长时间的锁，导致授权接口阻塞。etcd 3.4.9 之后缩小锁范围，可一定程度降低授权接口被阻塞的问题。



### 1.7 expensive request、treeIndex 锁

从 treeIndex 中获取整个查询涉及的 key 列表版本号信息。在这个流程中，影响其性能的关键因素是 treeIndex 的总 key 数、查询的 key 数、获取 treeIndex 锁的耗时。

* 首先，treeIndex 中总 key 数过多会适当增大我们遍历的耗时。
* 其次，若要访问 treeIndex 我们必须获取到锁，但是可能其他请求如 compact 操作也会获取锁。这就会导致其他请求阻塞，进而增大延时。
  * 为了解决这个性能问题，优化方案是 compact 的时候会将 treeIndex 克隆一份，以空间来换时间，尽量降低锁阻塞带来的超时问题。
* 然后就是 expensive read request，查询 key 数较多会使得流程七、八就会遍历大量的 key，导致请求耗时突增、内存上涨、性能急剧下降。

如果业务就是有这种 expensive read request 逻辑，我们该如何应对呢？

* 首先我们可以尽量减少 expensive read request 次数，在程序启动的时候，只 List 一次全量数据，然后通过 etcd Watch 机制去获取增量变更数据。
  * 比如 Kubernetes 的 Informer 机制，就是典型的优化实践。
* 其次，在设计上评估是否能进行一些数据分片、拆分等，不同场景使用不同的 etcd prefix 前缀。
  * 比如在 Kubernetes 中，不要把 Pod 全部都部署在 default 命名空间下，尽量根据业务场景按命名空间拆分部署。即便每个场景全量拉取，也只需要遍历自己命名空间下的资源，数据量上将下降一个数量级。
* 再次，如果你觉得 Watch 改造大、数据也无法分片，开发麻烦，你可以通过分页机制按批拉取，尽量减少一次性拉取数万条数据。
* 最后，如果以上方式都不起作用的话，你还可以通过引入 cache 实现缓存 expensive read request 的结果，不过应用需维护缓存数据与 etcd 的一致性。



### 1.8 大 key-value、boltdb 锁

从流程七获取到 key 列表及版本号信息后，我们就可以访问 boltdb 模块，获取 key-value 信息了。在这个流程中，影响其性能表现的，除了我们上面介绍的 expensive read request，还有大 key-value 和锁。

首先是大 key-value，非常容易导致 etcd OOM、server 节点出现丢包、性能急剧下降等。

其次是锁，etcd 为了提升 boltdb 读的性能，从 etcd 3.1 到 etcd 3.4 版本，分别进行过几次重大优化，在下一节中我将和你介绍。



## 2. 小结

* 首先我们可通过 etcd clientv3 自带的 Round-robin 负载均衡算法或者 Load Balancer，尽量确保整个集群**负载均衡**。
* 然后，在开启鉴权场景时，建议你**尽量使用证书**而不是密码认证，避免校验密码的昂贵开销。
* 其次，根据业务场景**选择合适的读模式**，串行读比线性度性能提高 30% 以上，延时降低一倍。线性读性能受节点之间 RTT 延时、磁盘 IO 延时、当前写 QPS 等多重因素影响。
* 最容易被大家忽视的就是**写 QPS 对读 QPS 的影响**，读 QPS 下降除了以上原因之外还可能是被 写 QPS 影响了。
* 你需要**遵循最佳实践**，避免一个请求查询大量 key、大 key-value 等，否则会导致读性能剧烈下降。

